{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://www.cnblogs.com/jasonfreak/p/5448385.html\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    " \n",
    "#导入IRIS数据集\n",
    "iris = load_iris()\n",
    "\n",
    "#特征矩阵\n",
    "iris.data\n",
    "\n",
    "#目标向量\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90068117,  1.03205722, -1.3412724 , -1.31297673],\n",
       "       [-1.14301691, -0.1249576 , -1.3412724 , -1.31297673],\n",
       "       [-1.38535265,  0.33784833, -1.39813811, -1.31297673],\n",
       "       [-1.50652052,  0.10644536, -1.2844067 , -1.31297673],\n",
       "       [-1.02184904,  1.26346019, -1.3412724 , -1.31297673]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#标准化，返回值为标准化后的数据\n",
    "StandardScaler().fit_transform(iris.data)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22222222,  0.625     ,  0.06779661,  0.04166667],\n",
       "       [ 0.16666667,  0.41666667,  0.06779661,  0.04166667],\n",
       "       [ 0.11111111,  0.5       ,  0.05084746,  0.04166667],\n",
       "       [ 0.08333333,  0.45833333,  0.08474576,  0.04166667],\n",
       "       [ 0.19444444,  0.66666667,  0.06779661,  0.04166667]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#区间缩放，返回值为缩放到[0, 1]区间的数据\n",
    "MinMaxScaler().fit_transform(iris.data)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.80377277,  0.55160877,  0.22064351,  0.0315205 ],\n",
       "       [ 0.82813287,  0.50702013,  0.23660939,  0.03380134],\n",
       "       [ 0.80533308,  0.54831188,  0.2227517 ,  0.03426949],\n",
       "       [ 0.80003025,  0.53915082,  0.26087943,  0.03478392],\n",
       "       [ 0.790965  ,  0.5694948 ,  0.2214702 ,  0.0316386 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#归一化，返回值为归一化后的数据: 0~1\n",
    "Normalizer().fit_transform(iris.data)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  0.,  0.],\n",
       "       [ 1.,  1.,  0.,  0.],\n",
       "       [ 1.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "#二值化，阈值设置为3，返回值为二值化后的数据\n",
    "Binarizer(threshold=3).fit_transform(iris.data)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (4, 0)\t1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#OneHotEncode 哑编码，对IRIS数据集的目标值，返回值为哑编码后的数据\n",
    "print OneHotEncoder().fit_transform(iris.target.reshape((-1,1)))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2092.0546666666669"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import vstack, array, nan\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "#缺失值计算，返回值为计算缺失值后的数据\n",
    "#参数missing_value为缺失值的表示形式，默认为NaN\n",
    "#参数strategy为缺失值填充方式，默认为mean（均值）\n",
    "Imputer().fit_transform(vstack((array([nan, nan, nan, nan]), iris.data))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150, 15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#多项式转换\n",
    "#参数degree为度，默认值为2\n",
    "print iris.data.shape\n",
    "print PolynomialFeatures().fit_transform(iris.data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.80828877,  1.5040774 ,  0.87546874,  0.18232156],\n",
       "       [ 1.77495235,  1.38629436,  0.87546874,  0.18232156],\n",
       "       [ 1.74046617,  1.43508453,  0.83290912,  0.18232156],\n",
       "       [ 1.7227666 ,  1.41098697,  0.91629073,  0.18232156],\n",
       "       [ 1.79175947,  1.5260563 ,  0.87546874,  0.18232156]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import log1p\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "#自定义转换函数为对数函数的数据变换\n",
    "#第一个参数是单变元函数\n",
    "FunctionTransformer(log1p).fit_transform(iris.data)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150, 1)\n",
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]]\n",
      "[[ 1.4]\n",
      " [ 1.4]\n",
      " [ 1.3]\n",
      " [ 1.5]\n",
      " [ 1.4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "#方差选择法，返回值为特征选择后的数据\n",
    "#参数threshold为方差的阈值\n",
    "print iris.data.shape\n",
    "data = VarianceThreshold(threshold=3).fit_transform(iris.data)\n",
    "print data.shape\n",
    "print iris.data[:5]\n",
    "print data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# 选择K个最好的特征，返回选择特征后的数据\n",
    "# 第一个参数为计算评估特征是否好的函数，该函数输入特征矩阵和目标向量，输出二元组（评分，P值）的数组，\n",
    "# 数组第i项为第i个特征的评分和P值。在此定义为计算相关系数参数k为选择的特征个数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.4,  0.2],\n",
       "       [ 1.4,  0.2],\n",
       "       [ 1.3,  0.2],\n",
       "       [ 1.5,  0.2],\n",
       "       [ 1.4,  0.2]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#选择K个最好的特征，返回选择特征后的数据\n",
    "SelectKBest(chi2, k=2).fit_transform(iris.data, iris.target)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named minepy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-18dafd673786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mminepy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMINE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#由于MINE的设计不是函数式的，定义mic方法将其为函数式的，返回一个二元组，\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 二元组的第2项设置成固定的P值0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named minepy"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from minepy import MINE\n",
    "\n",
    "#由于MINE的设计不是函数式的，定义mic方法将其为函数式的，返回一个二元组，\n",
    "# 二元组的第2项设置成固定的P值0.5\n",
    "def mic(x, y):\n",
    "    m = MINE()\n",
    "    m.compute_score(x, y)\n",
    "    return (m.mic(), 0.5)\n",
    "\n",
    "#选择K个最好的特征，返回特征选择后的数据\n",
    "SelectKBest(lambda X, Y: array(map(lambda x:mic(x, Y), X.T)).T, k=2).fit_transform(\n",
    "    iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.5,  0.2],\n",
       "       [ 3. ,  0.2],\n",
       "       [ 3.2,  0.2],\n",
       "       [ 3.1,  0.2],\n",
       "       [ 3.6,  0.2]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#递归特征消除法，返回特征选择后的数据\n",
    "# 递归消除特征法使用一个基模型来进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练。\n",
    "#参数estimator为基模型\n",
    "#参数n_features_to_select为选择的特征个数\n",
    "RFE(estimator=LogisticRegression(), n_features_to_select=2).fit_transform(\n",
    "    iris.data, iris.target)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4],\n",
       "       [ 4.9,  3. ,  1.4],\n",
       "       [ 4.7,  3.2,  1.3],\n",
       "       [ 4.6,  3.1,  1.5],\n",
       "       [ 5. ,  3.6,  1.4]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 使用带惩罚项的基模型，除了筛选出特征外，同时也进行了降维。使用feature_selection库的\n",
    "# SelectFromModel类结合带L1惩罚项的逻辑回归模型，来选择特征的代码如下：\n",
    "#带L1惩罚项的逻辑回归作为基模型的特征选择\n",
    "SelectFromModel(LogisticRegression(penalty=\"l1\", C=0.1)).fit_transform(\n",
    "    iris.data, iris.target)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.4,  0.2],\n",
       "       [ 1.4,  0.2],\n",
       "       [ 1.3,  0.2],\n",
       "       [ 1.5,  0.2],\n",
       "       [ 1.4,  0.2]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#GBDT作为基模型的特征选择\n",
    "SelectFromModel(GradientBoostingClassifier()).fit_transform(iris.data, iris.target)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.68420713,  0.32660731],\n",
       "       [-2.71539062, -0.16955685],\n",
       "       [-2.88981954, -0.13734561],\n",
       "       [-2.7464372 , -0.31112432],\n",
       "       [-2.72859298,  0.33392456]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#主成分分析法，返回降维后的数据\n",
    "#参数n_components为主成分数目\n",
    "PCA(n_components=2).fit_transform(iris.data)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.0849532 ,  0.32845422],\n",
       "       [ 7.1471629 , -0.75547326],\n",
       "       [ 7.51137789, -0.23807832],\n",
       "       [ 6.83767561, -0.64288476],\n",
       "       [ 8.15781367,  0.54063935]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "#线性判别分析法，返回降维后的数据\n",
    "#参数n_components为降维后的维数\n",
    "LDA(n_components=2).fit_transform(iris.data, iris.target)[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
